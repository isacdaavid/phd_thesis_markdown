# Antecedentes

## Bases neurales de las emociones

El conocimiento de las bases nerviosas de las emociones tuvo inicios
tumultuosos y sigue sufriendo cambios y refinamientos. El destacado
filósofo y pionero de la psicología, William James, leyó _The
Expression of the Emotions in Man and Animals_ [@darwin-1872] y
encontró inspiración para lanzar abiertamente la pregunta a la
comunidad científica: ¿qué es una emoción?, no sólo en términos
etológicos y evolutivos como incitó Darwin, sino también
neuropsicológicamente hablando [@james-1884]. La primera propuesta,
debida a él y Carl Lange, conforme al conocimiento de la época fue que
habría regiones en la corteza para evaluar la información sensorial y
otras para controlar efectores de respuesta [@james-1884;
@cannon-1927]. También se decía que las sensaciones o sentimientos
resultaban de que el cerebro se percatara de los cambios periféricos
que él mismo había solicitado. En otras palabras, que no eran
consecuencia directa de experimentar los estímulos, sino de
experimentar el componente fisiológico de la emoción. Aunque los
modelos neurobiológicos han cambiado bastante desde entonces, el
ordenamiento de la cadena causal de eventos que llevan a un
sentimiento es tema recurrente en las pesadillas de los estudiosos
contemporáneos de la emoción.

![Teoría James-Lange de la emoción. Tanto la evaluación de carga
emocional en el estímulo o evento interno, la producción de una
respuesta descendente y el sentimiento son la prerrogativa de partes
indefinidas de la corteza cerebral. Nótese cómo los sentimientos
ocurren tardíamente con la retroalimentación
ascendente. \label{james-lange}](source/figures/history-1.svg){height=25%}

Más tarde, fisiólogos de renombre como Charles Scott Sherrington y
Walter B. Cannon mostraron experimentalmente que respuestas
emocionales innatas eran posibles en animales completamente
decorticados y en otros donde se había desconectado el sistema
nervioso autonómico, pero no en ausencia del tálamo e hipotálamo
[@sherrington-1900; @cannon-1927]. Algo andaba muy mal con la teoría
de James-Lange. El nuevo modelo con piedra angular en el diencéfalo,
bautizado como de Cannon-Bard, fue complicándose con la adición
teórica del giro límbico o cingulado y del hipocampo, según las
observaciones de conectividad anatómica de James Papez [@papez-1937];
así como el descubrimiento de funciones viscerales [@triarhou-2008]
para esta corteza "límbica" o "anillada", y correlaciones entre la
conducta agresiva de la rabia y sus efectos morfométricos en el
hipocampo [@eysenck-2004]. Paul MacLean extendió el circuito de Papez
con más estructuras perihipocampales y de línea media en lo que se
conoce como "sistema límbico"[^triune], y consolidó la promesa del
hipocampo como habitáculo de los sentimientos [@maclean-1949]. Esto
venía motivado por descubrimientos recientes de que la disección de
los lóbulos temporales en monos generaba respuestas emocionales
completamente erráticas [@kluver-bucy-1937].

[^triune]: Que figuraba prominentemente en su desacreditada teoría de
    neuroetología evolutiva: el cerebro triúnico
    [@cesario-et-al-2020], de gran aceptación aún entre el público
    general.

![Progresión de modelos en el linaje de Cannon-Bard, tomando como
punto de partida el descubrimiento de la suficiencia del tálamo y los
núcleos del hipotálamo posterior para coordinar enojos innatos. Cannon
supo sintetizar los descubrimientos de Sherrington, los de Bard y los
propios para proponer una nueva visión _cerebrocentrista_ de las
emociones: la teoría de los núcleos talámicos o teoría central; que
cimbró empíricamente a la de William James. Papez y MacLean harían
adiciones parcialmente
acertadas. \label{cannon-bard}](source/figures/history-2.svg){height=30%}

El sistema límbico sufrió un primer golpe después del famoso paciente
H.M. [@ledoux-damasio-2013], pues se mostró que las funciones del
hipocampo, hasta entonces desconocidas, eran completamente
distintas. Sin embargo quedaba la incertidumbre de a qué estructura
temporal se debían esas anomalías emocionales. Fue el psicólogo
Lawrence Weiskrantz, conocido también por el fenómeno de "blindsight",
quien descubrió que se trataba de la amígdala, no del hipocampo
[@weiskrantz-1956]. Desde entonces la amígdala figura como una pieza
clave para evaluar la carga emocional de los estímulos y aprender
inconscientemente a asociar ciertas situaciones con ciertas respuestas
emocionales.

A grandes rasgos, los impulsos tempranos que entran al tálamo son
copiados a cortezas sensoriales pero también a la amígdala en cada
hemisferio, especialmente sus núcleos laterales
[@ledoux-damasio-2013]. Éstos últimos se especializan en detectar
eventos emocionalmente relevantes. Una larga historia de investigación
en condicionamiento iniciada por Weiskrantz ha mostrado que la
amígdala debe estar forzosamente presente para aprender a asociar
implícitamente conductas y estímulos condicionados con el miedo,
aunque por sí sola no es suficiente [@ledoux-damasio-2013]. Por
ejemplo: cuando un niño aprende a no introducir sus dedos en una toma
de corriente, sus amígdalas hacen posible que la respuesta de miedo se
"copie" de la experiencia intrínsecamente aversiva de una descarga
eléctrica a la mera observación de la toma de corriente (siguiendo una
lógica de condicionamiento clásico). Luego el núcleo central de cada
amígdala proyecta a lugares como el hipotálamo y la sustancia gris
periacueductal (PGA) del mesencéfalo, que a su vez activan,
respectivamente, actividad humoral estresante en el eje
hipofisiario-adrenal y conductas motoras automáticas
[@ledoux-damasio-2013].

![La amígdala se incorpora como pieza irrenunciable del sistema de las
emociones. \label{weiskrantz}](source/figures/history-3.svg){height=25%}

Hoy en día se reconoce ampliamente que algunas zonas de la corteza
también juegan un papel en el sistema emocional. De alguna manera
siempre fue sospechado, gracias a casos como el de Phineas Gage y
demás pacientes con lesiones que llevaron a conductas sociopáticas
[@ledoux-damasio-2013]. Las regiones en cuestión son la corteza
prefrontal ventral y medial alrededor de los giros rectos[^pfc]
[@bechara-et-al-2000], la corteza del cíngulo anterior más ventral
(vACC) [@bush-et-al-2000; @allman-et-al-2001], contigua a los giros
rectos y ya mencionada como parte del sistema límbico; además de los
lóbulos de las ínsulas en sus porciones más anteriores y
ventrales[^salience] (vAIC) [@gu-et-al-2013; @alcauter-et-al-2015].

[^pfc]: Corteza prefrontal ventromedial (vmPFC), aunque a veces el
       énfasis se hace más lateral, hacia la parte orbitofrontal
       (OFC).
[^salience]: Curiosamente, tanto la ínsula anterior como el cíngulo
    anterior mantienen la misma subdivisión durante su fuerte
    interacción en funciones emocionales y de
    monitoreo/autorregulación. Mientras que el cíngulo anterior dorsal
    y la ínsula anterior dorsal se han asociado a la red de saliencia
    en estudios en estado de reposo, sus contrapartes ventrales están
    estrechamente ligadas a la emoción.

![El entendimiento contemporáneo del sistema emocional abarca varios
componentes corticales e incluso cerebelosos. En imagen se muestran
áreas sugeridas por Damasio, incluyendo la corteza somatosensorial
primaria [@ledoux-damasio-2013]. \label{somatic-marker}](source/figures/history-4.svg){height=25%}

En este punto se han acumulado cientos de estudios sobre los
correlatos neurales de las emociones, sin embargo no han podido
responderse preguntas un poco más refinadas, como cuáles son las
marcas ya no de las emociones como un todo, sino de cada emoción en
particular. La localización y codificación de emociones tanto en el
sistema nervioso central como en el periférico permanece un problema
abierto [@kragel-labar-2016; @celeghin-et-al-2017]. Una pregunta
fundamental es si existen patrones en actividad neuronal
suficientemente específicos que correspondan con concepciones
vernáculas y académicas de las emociones. Además, ¿qué tan
generalizables son esos correlatos entre individuos y especies?  Esta
última cuestión tiene acaloradas implicaciones para la comprensión de
la aparición de estados afectivos, ya sea en términos de evolución
genética o cultural.

Una técnica o familia de técnicas que resulta especialmente útil para
mapear funciones cerebrales tan distribuidas (como las emociones) es
la neuroimagen funcional.[^neuroimagenfunc] Desafortunadamente, los
metanálisis y revisiones de la literatura no muestran una tendencia en
la respuesta a las preguntas anteriores. @phan-et-al-2002 analizaron
los mapas de activación de 55 estudios de PET[^pet] y fMRI[^fmri], y
encontraron evidencia parcial para la existencia de correlatos
neuroanatómicos consistentes a la ocurrencia de distintos tipos de
emociones básicas. @murphy-et-al-2003 incrementaron el tamaño de
muestra a 106 estudios y mantuvieron la conclusión general respecto
del metanálisis anterior, aunque los correlatos no fueron
suficientemente similares. La relativa debilidad de los resultados ha
sido usada como evidencia de hipótesis alternativas; a saber, teorías
dimensionales y de actos conceptuales [emociones como construcciones
de afectos, @barrett-2006]. @barrett-wager-2006 examinaron 161
estudios y encontraron correlatos exclusivos (mas no específicos) para
miedo, tristeza y asco. La felicidad y el enojo no arrojaron
correlatos ni consistentes ni específicos. @vytal-and-hamann-2010
utilizaron un análisis con mayor sensibilidad espacial para contrastar
cinco emociones básicas provenientes de 83 estudios. Concluyeron que
aunque existen _clusters_ característicos de activación para cada una
de ellas, no es evidencia suficiente para descartar otros modelos de
representación emocional en el cerebro. @lindquist-et-al-2012
analizaron 91 estudios tanto de experiencia de emociones como de
percepción emocional. Definieron evidencia a favor de emociones
básicas como actividad consistente en áreas específicas selectivas a
una única categoría. Se encontró consistencia y selectividad para las
cinco categorías bajo consideración, mas no especificidad
funcional. Es decir, las escurridizas emociones básicas tendrían
correlatos distinguibles entre sí, aunque las mismas regiones
cerebrales están vinculadas a otras funciones psicológicas
extraemocionales.

[^neuroimagenfunc]: El uso de imágenes cerebrales para medir algún
    aspecto de la actividad cerebral, y que abarca técnicas tan
    diversas como el EEG (electroencefalograma, al mismo tiempo una
    técnica electrofisiológica), MEG (magnetoencefalograma,
    estrechamente relacionada al EEG), fNIRS (espectroscopía cercana
    al infrarrojo), SPECT (tomografía computarizada por emisión de
    fotón único), ultrasonido funcional, PET y fMRI.
[^pet]: Positron Emission Tomography: tomografía por emisión de positrones
[^fmri]: Functional Magnetic Resonance Imaging: imagenología de
    resonancia magnética funcional.

Quizás la manera más efectiva de comunicar semejante discurrencia sea
con el siguiente contraste entre dos citas a los resúmenes de los dos
metanálisis más recientes:

> "Each of the emotions examined [...] was characterized by consistent
> neural correlates across studies, as defined by reliable
> correlations with regional brain activations. In addition, the
> activation patterns associated with each emotion were discrete
> (discriminable from the other emotions [...])".
> @vytal-and-hamann-2010.

> [W]e found little evidence that discrete emotion categories can be
> consistently and specifically localized to distinct brain
> regions. Instead, we found evidence that is consistent with a
> psychological constructionist approach". @lindquist-et-al-2012.

No pueden ambos estar en lo correcto.

El consenso disponible (y casi unánime) es que la búsqueda de
estructuras específicas a un tipo de emoción está superada
[@murphy-et-al-2003; @kober-et-al-2008;
@lindquist-et-al-2012]. Estructuras cerebrales que parecían tener una
correspondencia uno-a-uno con alguna emoción básica, como la amígdala
(miedo) y la ínsula (asco) [@calder-et-al-2001], ahora son acreedoras
a funciones más elusivas o generales [@sander-et-al-2003]. Además, si
la función emocional tiene biomarcadores reproducibles, su
decodificación[^decodificación] dependerá de la actividad conjunta de
redes funcionales distribuidas y traslapadas [@hamann-2012;
@lindquist-barrett-2012; @kragel-labar-2014; @celeghin-et-al-2017;
aunque comparativamente no se han realizado tantos estudios usando
técnicas de electrofisiología, la revisión realizada por
@guillory-bujarski-2014 concuerda con esta conclusión].

[^decodificación]: (De)codificación es un término importado de la
    teoría de la información para referirse a la transformación de la
    información de una representación a otra. En neurociencia
    computacional, codificación refiere específicamente al
    conocimiento y aplicación de las funciones matemáticas que
    convierten estímulos o entradas sinápticas a su respectiva
    actividad de salida (ej. potenciales de acción). Decodificación es
    el proceso inverso: inferir entradas a partir de salidas.

En este sentido, el campo de neurociencia afectiva aunado a técnicas
como fMRI ha promovido ampliamente la incorporación de nuevos métodos
de análisis, especialmente métodos multivariados,[^multivariado]
puesto que podrían ofrecer mayor sensibilidad para responder la
pregunta de los correlatos de las escurridizas emociones. Antes de
poder contrastar las bondades y operaciones de éstos contra el
análisis clásico se precisará recordar brevemente el origen de las
señales más usualmente buscadas en fMRI: las señales BOLD o
"dependientes del nivel de oxígeno en la sangre".

[^multivariado]: Se usa el calificativo "multivariado" en el sentido
    estadístico y matemático: que trabaja con funciones de múltiples
    variables.

## Resonancia magnética y el efecto BOLD

Cuando de registrar actividad cerebral con la mayor envergadura y
resolución espacial se trata, la técnica más conspicua actualmente es
la resonancia magnética nuclear funcional. Escáneres modernos de este
tipo son capaces de registrar casi simultáneamente una forma de
metabolismo aeróbico en todas las partes de una malla virtual, que
bien podría cubrir la totalidad del encéfalo. La resolución temporal
de estas señales, conocidas como "BOLD", difícilmente puede ir por
debajo de una muestra cada 1 ó 2 segundos. Sin embargo, se sabe que
esta forma de actividad fisiológica está correlacionada con el
potencial de campo local de los ensambles de neuronas involucradas
[@logothetis-et-al-2001]; si bien se sabe menos de los mecanismos
detrás del acoplamiento entre ambos fenómenos. Es una técnica idónea
para estudios en los que redes funcionales asociadas a tareas primero
deben ser identificadas o refinadas — _in vivo_ y sin invasividad —
allanando el terreno para técnicas de medición más finas que intenten
establecer la circuitería y química sináptica
[@logothetis-2008]. Estos párrafos pretenden esbozar los fundamentos
físicos de la resonancia magnética nuclear en general, y su aplicación
al estudio de la función cerebral como representante tácito de muchas
otras aplicaciones que se le han encontrado tan solo en el campo de
las imágenes médicas.

El efecto BOLD se ha convertido en la forma más común de hacer
fMRI. Éste fue descubierto (o quizás redescubierto) por Seiji Ogawa y
colaboradores en una serie de estudios al inicio de la década de 1990
[@ogawa-et-al-1990; @ogawa-lee-1990; @ogawa-et-al-1990-2;
@ogawa-et-al-1992]. La señal BOLD es una medida indirecta de los
incrementos y disminuciones de actividad neuronal. Ante una fuerte
demanda metabólica de las neuronas, mecanismos diversos de
acoplamiento neurovascular responden provocando vasodilatación para
compensar la extracción del oxígeno en los eritrocitos que van pasando
por los capilares aledaños (ver figura \ref{bold}). Más incluso, la
compensación es una _sobrecompensación_ [@uludag-et-al-2005]; por lo
que el balance neto conforme aumenta la tasa de disparo de potenciales
de acción (junto con otros fenómenos celulares) es hacia la hiperemia
e hiperoxia. Décadas atrás, el famoso químico Linus Pauling había
descubierto que la molécula de la hemoglobina presenta una
susceptibilidad magnética distinta dependiendo de si los dominios con
hierro portan o no oxígeno [@pauling-coryell-1936]. Se puede imaginar
que mientras que la versión oxigenada de la hemoglobina preserva el
flujo del campo magnético en el que está inmerso el tejido, su
contraparte desoxigenada lo deforma. Es entonces cuando la prestación
del fenómeno a ser cuantificado mediante resonancia magnética se
vuelve natural y patente: la señal BOLD como fluctuación
electromagnética es una función de la tasa metabólica de oxígeno en la
sangre local y, sobretodo, del flujo sanguíneo [@uludag-et-al-2005].

Todas las aplicaciones usuales de resonancia magnética nuclear buscan
excitar el _espín_ de algún isótopo particular, usualmente hidrógeno
protio ($^{1}H$) en el ambiente imagenológico, de gran abundancia en
las moléculas de agua y biomoléculas. Los espínes yacen en un estado
basal de energía, alineados preponderantemente como brújulas en
dirección del fuerte campo del magneto externo, hasta que un pulso
electromagnético sintonizado a su frecuencia natural de resonancia los
hace pasar a otro estado excitado en dirección opuesta. Según los
protones van relajándose al estado inicial, la energía
electromagnética es disipada de vuelta; no obstante, aquellos que se
encuentran en un campo magnético diezmado se desfasan más rápidamente
en su giro en precesión; por lo que la señal transversal al campo
magnético principal, tal y como es obtenida en una región del tejido,
es menor cuando la actividad neuronal y el flujo de sangre oxigenada
es menor. Ésta es la resonancia magnética nuclear que subyace
aplicaciones como el efecto BOLD, condensada a una cáscara de
nuez. ¿Pero qué significaría todo eso con algo más de detalle?

[^bold]: Neuron Silhouette [@scidraw-2020].

El espín ($S$) es una de las propiedades fundamentales de la materia
según la física contemporánea, al igual que la carga electromagnética
y la masa. El espín es una forma de ímpetu angular o cantidad de
movimiento angular (también llamado "momento angular"), como el giro
de una rueda o la traslación de los planetas a través de su órbita. A
diferencia de esos momentos angulares, el espín se distingue por ser
un movimiento en ausencia de cambio de posición; dicho de otra manera,
un giro "sobre su propio eje", como la rotación de la Tierra. Para
sorpresa de los físicos de la década de 1920, el espín resultó ser más
que una descripción sumaria de un desplazamiento cíclico de varias
partículas (como las que conforman la Tierra en rotación), sino que se
encuentra de forma muy sofisticada en las escalas más microscópicas e
indivisibles del Universo. Este espín fundamental fue propuesto en
primer lugar como aditamento a la mecánica cuántica básica del
electrón [@pauli-1924; @uhlenbeck-goudsmit-1925; @pauli-1927],
poniendo fin a los misteriosos resultados de experimentos como el de
Stern-Gerlach [@gerlach-stern-1922-1; @gerlach-stern-1922-2] y el
efecto Zeeman [@preston-1898].

![Fisiología y física básicas de la señal BOLD. __A__: unión
neuro-astrocítica-vascular provoca vasodilatación además de consumir
una fracción del oxígeno hematogénico del capilar. __B__: efecto del
fenómeno fisiológico sobre el campo magnético, y cómo es aprovechado
para medir una señal dependiente de la actividad
sanguínea. Créditos.[^bold]
\label{bold}](source/figures/bold-effect.svg){width=65%}

Como propiedad intrínseca a cada partícula fundamental o campo
cuántico, el espín expresa la magnitud de algo abstracto, aunque
concebible en un primer abordaje como la rotación que sufre un punto
en el espacio sobre sí mismo antes de regresar a la configuración de
inicio.[^kroning] Más propiamente, se trata de una transformación en
un espacio puramente matemático, interno a la partícula o asociado a
ésta, sin tratarse de una rotación de la partícula misma
[@pauli-1927].

[^kroning]: Ralph Kroning ofreció en 1925 dicha interpretación física
    para la primera formulación de @pauli-1924; pero éste último la
    rechazó porque la rotación sería más rápida que $c$.

Por lo tanto el espín se concibe como cantidad vectorial: además de
magnitud, posee dirección o signo que está sujeto a cambios, si bien
son cambios discretos. Sistemas de partículas como bariones y núcleos
atómicos enteros también pueden acumular un espín distinto de 0,
siempre que el número de neutrones o protones sea impar. El espín como
momento angular se calcula a partir del número cuántico de espín
($s$), magnitud adimensional que solo toma valores múltiplos de
$\frac{1}{2}$, según las indagaciones experimentales que se han hecho
desde Stern y Gerlach. Este hecho empírico puede ser difícil de
asimilar, sin embargo dio pauta a tan peculiar desarrollo
matemático. Por ejemplo, los únicos valores posibles para el $s$ del
$^{1}H$ congruentes con sus efectos medibles como momento angular y
momento magnético son $+\frac{1}{2}$ y $-\frac{1}{2}$. Obtener $S$ a
partir de $s$ simplemente conlleva multiplicar por $\hbar$: la
constante reducida de Planck [@brown-et-al-2014].

Como en cualquier esquema de mecánica cuántica, el estado del sistema
existe en un espacio de Hilbert con tantas dimensiones como estados
observables, de manera que el $S$ del $^{1}H$ — antes de ser medido —
puede estar en una superposición de ambas posibilidades. Esto se
modela como el vector unitario $\bm{s}$ (o el _ket_ $\left|\left. S
\right>\right.$ siguiendo notación de Dirac). Para el caso no
relativista de partículas con espín $\frac{1}{2}$ se tiene [@brown-et-al-2014]:

$$ \left|\left. S \right>\right. = \bm{s} = \begin{pmatrix} a \\ b \end{pmatrix} \;\;\;\; a,b \in \mathbb{C}; \;\;\;\; |a|^2+|b|^2=1 $$ {#eq:}

El vector complejo $\bm{s}$ también es conocido como un
_espinor_.[^bloch-sphere] Siguiendo la regla de Born, $|a|^2$ y
$|b|^2$ son las probabilidades de observar $S$ como $+\hbar/2$ ó
$-\hbar/2$.

[^bloch-sphere]: Otra representación popular equivalente para sistemas
    de dos niveles (qubits) como el espín del $^{1}H$ es la superficie
    de la esfera de Bloch.

Es claro que elegir entre $a$ o $b$ para representar el signo es
meramente arbitrario, por lo que se necesita un método de cambio de
coordenadas para que distintos experimentadores traduzcan sus
resultados, y para seguir la pista dinámica del sistema conforme
evolucione según la ecuación de Schrödinger. Sin embargo, al tratarse
de vectores complejos, no es posible traducir el estado cuántico
$\bm{s}$ entre rotaciones de los ejes usando el grupo de matrices
$SO(3)$ para espacio euclidiano 3D. Ejemplo insólito de ello es que si
uno midiera el espín de un átomo de hidrógeno estático, llamara a eso
$\left|\left. \uparrow \right>\right.$, lo rotara 360° y luego
volviera a medir; ¡el espín observado de hecho sería el opuesto a
$\left|\left. \uparrow \right>\right.$! [@brown-et-al-2014].

Mientras tanto, en espacio 3D la medición de $S$ requiere de una base
con tres observables ($S_x$, $S_y$ y $S_z$ en coordenadas
cartesianas). Por lo tanto, para rotar un espín $\frac{1}{2}$ se
precisa una base de operadores lineales de $2 \times 2$, que
llamaremos $\bm{\Sigma_x}$, $\bm{\Sigma_y}$ y $\bm{\Sigma_z}$ (las
matrices de Pauli). Como todo operador en mecánica cuántica, además
deben ser autoadjuntos (matrices Hermitias) y deben cumplir que
$det(\bm{\Sigma})=1$ para preservar la probabilidad o norma de
$\bm{s}$, y sus _eigenvectores_ (también llamados autovectores o
vectores propios) deberían ser los únicos estados posibles (en este
caso: $(+\hbar/2, \; 0)^T$ y $(0, \; -\hbar/2)^T$); de modo que existe
la certeza de que el operador jamás convertirá estados posibles en
estados imposibles.

Aquí es donde el álgebra abstracta y la teoría de grupos no abelianos
salvan el día, encontrando una simetría homomórfica de tipo
sobreyectivo entre el grupo de Lie $SO(3)$ ("special orthogonal") para
componer rotaciones continuas en espacio físico, con base ortonormal
canónica:

$$ \begin{pmatrix} 0 & 0 & 0 \\ 0 & 0 & -1 \\ 0 & 1 & 0 \end{pmatrix},
   \begin{pmatrix} 0 & 0 & 1 \\ 0 & 0 & 0 \\ -1 & 0 & 0 \end{pmatrix},
   \begin{pmatrix} 0 & -1 & 0 \\ 1 & 0 & 0 \\ 0 & 0 & 0 \end{pmatrix}; $$

y sus correspondientes matrices en el grupo $SU(2)$ ("special
unitary") [@brown-et-al-2014]:

$$ \bm{\Sigma_x} = \begin{pmatrix} 0 & 1 \\ 1 & 0 \end{pmatrix},
   \bm{\Sigma_y} = \begin{pmatrix} 0 & -i \\ i & 0 \end{pmatrix},
   \bm{\Sigma_z} = \begin{pmatrix} 1 & 0 \\ 0 & -1 \end{pmatrix}. $$ {#eq:}

A pesar de poder ahora modelar la evolución del espín en el espacio 3D
gracias a estas matrices de Pauli, el principio de incertidumbre
impide asignar valores definidos y simultáneos a los tres
componentes. Sin embargo, sigue siendo de gran utilidad pensar en este
vector cuando se toma en cuenta que el espín de la partícula en
mancuerna con su carga producen un _momento de dipolo magnético de
espín_, $\bm{\mu}$ , como si se tratase de una brújula que
experimentará realineación o torque conforme al campo magnético
[@brown-et-al-2014]:

$$ \bm{\mu}_S = \gamma \bm{s} $$ {#eq:}

Donde $\gamma$, llamada "_razón giromagnética_", es una constante
particular a cada partícula o sistema ya que está dada por su masa,
su carga y su factor-g, según $\gamma = gq/2m$.

Cuando el campo magnético es nulo, ambos estados de $s$ ($+\frac{1}{2}$
y $-\frac{1}{2}$) son equiprobables o de misma energía, pero en
presencia de un campo magnético $\bm{b}_0$, la energía de cada estado
será el producto interior [@brown-et-al-2014]:

$$ E = -  \bm{b}_0 \cdot \bm{\mu}_S $$ {#eq:energy-magnetic}

Si el campo es despreciable excepto en una dirección (llámese $z$),
como en el caso de un solenoide, la expresión (@eq:energy-magnetic) se
reduce a $E = -b_{0_z} \gamma \hbar s_z$. Es decir: que la energía
para cada estado es una función lineal de la magnitud del campo,
cambiando la pendiente según el signo de $s_z$. Lo que esto significa
para el tejido o muestra rodeado por un electroimán es que el espín de
todas sus partículas con un momento magnético se "realinea" en
dirección de $\bm{b}_0,$ o la exactamente opuesta, pero no en la misma
proporción.[^boltzmann] La ligera preferencia por ocupar estados de
menor energía se traduce en un _vector neto de magnetización de espín_
distinto de cero, llamado $\bm{m}$, para el cual el análisis puede
proseguir sin hacer alusión a la mecánica cuántica subyacente
[@brown-et-al-2014].

[^boltzmann]: La distrubución de Boltzmann nos dice que la
    probabilidad de encontrar $\bm{\mu}_S$ en uno u otro estado
    energético es (a temperatura $T$ y usando la constante homónima
    $k$):

    $$ P(E) = \frac{1}{\sum e^{-E_i/kT}} e^{-E/kT} $$

![Ruptura de los niveles de energía del momento magnético de espín de
un protón en presencia de un campo magnético externo. Imagen donada al
dominio público por J. Bancroft
Brown. \label{nmr-energy}](source/figures/NMR_splitting.gif){height=15%}

Si ese fuera el fin de la historia no habría resonancia ni
aplicaciones interesantes. Sin embargo resulta que, narrado de manera
un tanto informal, $\bm{m}$ no sólo gira incesantemente sobre su
propio eje debido al espín; y no sólo rota momentáneamente un poco más
con tal de volverse paralelo a $\bm{b_0}$. $\bm{m}$ además sufre
precesión: una reorientación cíclica alrededor del eje de $\bm{b_0}$,
similar a los tambaleos de un trompo desalineado en su giro. El
movimiento de $\bm{m}$ llevará por nombre y apellido "_precesión de
Larmor_".[^rabi] La frecuencia de la precesión de Larmor sólo depende
de la razón giromagnética y la magnitud de $\bm{b_0}$ [@brown-et-al-2014]:

$$ \nu = \frac{\omega}{2\pi} = \frac{\Delta E}{h} = \frac{-\gamma |\bm{b}_0|}{2\pi} $$ {#eq:}

[^rabi]: En una verdadera explicación cuántica se hablaría de
    oscilaciones de Rabi.

Mera sustitución de valores permite conocer cuál sería el límite de
intensidad del campo magnético antes de tener que exponer la muestra a
ondas ionizantes para lograr la precesión.

La resonancia propiamente es una característica matemática de toda
ecuación diferencial con soluciones ondulatorias a la cual se ha
añadido un término inhomogéneo (o sea que no depende de la
incógnita). Lo que sea que esté representando el término inhomogéneo
sirve como suministro de energía al sistema; y cuando esto ocurre en
sincronía a la ondulación natural, la energía es aprovechada para
excitar las oscilaciones.

Algo sobresaliente es que la precesión de Larmor existe por la mera
presencia del campo magnético estático, pero su amplitud es
contingente a que un campo $\bm{b}_1(t)$, oscilando a la frecuencia
adecuada en el plano $xy$, se monte en superposición con
$\bm{b}_0$. Más aún, el pulso resonante sincroniza la precesión. Entre
más duradera la pulsación de $\bm{b}_1(t)$, mayor la apertura del cono
que $\bm{m}$ forma mientras precesa. Inclusive podría pasar de
precesar en un cono alrededor de la dirección $z$ a girar como
manecilla sobre el plano ortogonal $xy$; con el origen del vector
siempre pinchado al origen de este marco de referencia imaginario. Un
pulso con el doble de duración ($t_p$) alimentaría suficiente energía
para invertir la precesión en la dirección $z$ opuesta. Así, los
pulsos de radiofrecuencia pueden ser identificados según su "flip
angle": de 90°, 180°, etc. Si la amplitud ($A$) del oscilador externo
$b_1(t) = A sin(\omega t + \varphi)$ es constante (pulso "cuadrado"),
entonces el ángulo obtenido se aproxima a [@brown-et-al-2014]:

$$ \angle (\bm{b}_{0_z}, \bm{m}) \approx \gamma A t_p $$ {#eq:}

Una vez que dicho pulso resonante haya cesado, el conjunto de espines
irá perdiendo la energía absorbida debido a la sarta de interacciones
que siguen ocurriendo entre ellos mismos y con el medio. El vector
$\bm{m}$ precesa en espiral de regreso al estado base. Imagine que el
sistema acaba de ser excitado con un pulso de resonancia de
90°. Mientras que $\bm{m}$ va perdiendo su componente en el plano
transversal "$xy$" a su regreso (relajación transversal), el eje $z$
lo ve recuperarse (relajación longitudinal). Dichos movimientos de
relajación son descritos clásicamente por el sistema de ecuaciones
diferenciales de Bloch, con parámetros de tiempo T1 (longitudinal) y
T2 (transversal), los cuales son característicos de cada compuesto o
tejido. De aquí que la señal electromagnética devuelta registrada por
una bobina-antena pueda ser más intensa en una zona del tejido que en
otra, o en dos momentos distintos para la misma zona de tejido como
sucede con el efecto BOLD [@brown-et-al-2014].

![Columna izquierda: $\bm{m}$ en precesión. Centro: $\bm{m}$ tras
aplicar un pulso resonante de 90° en $b_1$. Derecha: relajación de
vuelta al estado de inicio. Recuérdese que $\bm{m}$ es la suma de
varios momentos magnéticos de espines individuales. La precesión
inicial no tiene por qué ser coherente como en el diagrama, pero una
vez "tumbados" al plano $xy$, todos los espines entran en fase. La
velocidad de desfasamiento es crucial para el efecto
BOLD. \label{nmr}](source/figures/NMR.png){width=85%}

Se espera que el lector ahora tenga elementos suficientes para lograr
una lectura autocontenida del trabajo, sobre todo durante la
descripción del protocolo de imágenes en la sección de _Métodos_. Sin
embargo, cabe señalar que no se ha dicho nada al respecto del diseño
de secuencias de pulsos para obtener uno u otro tipo de imagen (pesada
a T1, pesada a T2, funcional, pesada a difusión, etc.), ni de cómo se
excita selectivamente una rebanada de la muestra, y cómo se
reconstruye la imagen a partir del simple muestreo de señales
unidimensionales que llegan a la antena y a partir de la transformada
inversa de Fourier. Al mismo tenor puede consultarse el libro de
@brown-et-al-2014.

## Análisis estadístico de patrones de actividad cerebral

### Análisis clásico

Es necesario visualizar en conjunto todas las señales de actividad
cerebral para entender en qué difiere el análisis clásico respecto del
análisis de patrones multivariados. El argumento es una abstracción
matemática y por lo tanto no se limita a considerar exclusivamente
los voxeles en una secuencia de fMRI y su señal BOLD. Los mismos
métodos de análisis son aplicables a registros con electrodos,
imágenes de microscopía de doble fotón de calcio o cualquier otra
forma de dinámica cerebral, fisiológica o de cualquier otro campo de
estudio.

Una característica de la señal de fMRI es su pobre razón con el ruido
y cambios netos de apenas entre el 1% y 3% sobre la línea base, que
además es arbitraria para cada voxel. Naturalmente, es imprescindible
un análisis estadístico riguroso para extraer información de
ellas. @friston-et-al-1994 introdujeron al mundo de la neuroimagen
funcional la forma de análisis que terminaría convirtiéndose en
estándar, en un exitoso intento por unificar las distintas
herramientas estadísticas lineales que iban aplicándose al incipiente
tipo de datos [por ejemplo, @friston-et-al-1991; @worsley-et-al-1992],
y que pretendían otorgar rigor y madurez a las (a veces) abyectas
interpretaciones y conclusiones de los estudios.

El análisis clásico busca ajustar un modelo de regresión lineal entre
las muestras de datos provenientes de dos o más series de tiempo: la
actividad fisiológica y cómo se presentaron los estímulos o cómo
aconteció la tarea. El afán es encontrar voxeles o pequeñas regiones
cuyas señales fisiológicas por sí solas se correlacionan altamente con
las variables manipuladas experimentalmente. Aunque el modelo de
regresión suele incorporar varias covariables predictoras[^regresores]
con información del movimiento del sujeto y otras formas de ruido
(para reducir la inflación del verdadero efecto experimental), no se
acostumbra incluir múltiples señales de actividad cerebral. De hecho,
no se incluye _ninguna_. En lugar de fungir como predictor del
experimento, la serie de tiempo de una región cerebral es la variable
a ser explicada mediante una combinación lineal o suma ponderada de la
variable experimental y covariables. Luego el algoritmo se repite por
separado para modelar la señal cerebral en otra zona. Por esta razón,
y un tanto erradamente, el análisis de regresión clásico también se
denomina "univariado masivo".

[^regresores]: También llamados "regresores" o simplemente "variables
            independientes".

La forma más general de análisis por regresión lineal
es el modelo lineal generalizado de efectos mixtos (GLMM), que en
notación matricial[^linop] reza:

[^linop]: O más generalmente, para operadores lineales de espacios
    vectoriales arbitrarios, discretos como matrices o continuos.

$$ \bm{Y} = g( \bm{X \Theta} + \bm{Z U} ) + \bm{\mathcal{E}} $$ {#eq:glme}

Donde $\bm{Y}$ es la matriz de vectores-columna de series de tiempo a
explicar (las observaciones de variables dependientes), $\bm{X}$ y
$\bm{Z}$ son matrices de diseño con vectores-columna de series de
tiempo de regresores (variables independientes); y $\bm{\Theta}$ y
$\bm{U}$ son las matrices de parámetros a estimar (efectos fijos y
efectos aleatorios, respectivamente). $g$ es una función de activación
arbitraria, no necesariamente lineal, pero que se aplica elemento a
elemento para preservar las dimensiones de su matriz
argumento. $\bm{\mathcal{E}}$ es el error o ruido, modelado como una variable
aleatoria que puede pertenecer a cualquier distribución de la familia
exponencial.

Si se elige la no-linealidad $g$ como la simple función identidad y se
asume ruido gaussiano, el modelo se reduce al modelo lineal de efectos
mixtos (LME, $\bm{\hat{Y}} = \bm{X}\bm{\Theta} + \bm{Z}\bm{U};\;
\bm{\mathcal{E}} \sim \mathcal{N}(0,\bm{\Sigma})$). Si se omiten los
efectos aleatorios, se obtiene un modelo lineal generalizado (GLM,[^generalised]
$\bm{\hat{Y}} = g(\bm{X}\bm{\Theta})$). En la
intersección entre ambas simplificaciones se encuentra el modelo
lineal general (GLM también,[^regression-history] $\bm{\hat{Y}} =
\bm{X}\bm{\Theta};\;\bm{\mathcal{E}} \sim \mathcal{N}(0,\bm{\Sigma})$).

[^generalised]: Inventado por @nelder-wedderburn-1972.
[^regression-history]: La idea de ajustar modelos lineales de
    regresión (y regresión lineal múltiple) puede ser trazada hasta
    los trabajos en astronomía matemática de @legendre-1805 y
    @gauss-1823. Más tarde serían retomados y elaborados en un
    contexto genético y estadístico por @yule-1897, @pearson-1903 y
    @fisher-1922.

El marco teórico del modelo lineal generalizado ya es suficientemente
maleable como para capturar diversos tipos de variable de respuesta
(booleana, categórica, entera, real, etc.)
[@nelder-wedderburn-1972]. Por ejemplo, los GLMs son modelos
descriptivos populares de la tasa de disparo de una
neurona. Dadas las series de tiempo de potenciales de neuronas
presinápticas y las observaciones de los potenciales de acción de la
neurona de interés, GLM aprende los pesos que debería poseer cada
sinapsis con el afán de que su combinación produzca la respuesta
observada (integración espacial de la información). Con algunos trucos
también podría aprender el filtro de convolución que determina la
contribución de cada potencial de entrada en el pasado
(des)polarizando la neurona en el presente (integración temporal).

De cualquier manera, la probabilidad empírica de observar cierto
número de espigas en la variable respuesta por unidad de tiempo no es
simétrica: no tiene sentido hablar de tasas de disparo negativas, y
hay un sesgo a disparar apenas terminado el periodo refractario, por
lo que el GLM se adapta con una distribución de probabilidad de
Poisson o una exponencial para modelar este tipo de aleatoriedad de la
respuesta. También se introduce una función $g$ que acomode este
cambio, respecto de cuando se usa ruido gaussiano para la regresión
lineal múltiple.

\small

| Tipo de GLM | $\bm{y}$ | $\bm{\mathcal{E}}$ | $g$ |
|-|-|-|-|
| regresión lineal | $\mathbb{R}$ | $\mathcal{N}(\mu,\sigma^2)$ | $\bm{X \Theta}$ (identidad) |
| regresión Poisson | $\mathbb{N}$ | $Poisson(\lambda)$ | $e^{\bm{X}\bm{\Theta}}$ (exponencial) |
| regresión logística | $\left\{0,1\right\}$ | $Bernoulli(p)$ | $\frac{1}{1+e^{-\bm{X \Theta}}}$ (sigmoide) |

Table: Algunas variantes comunes de modelos lineales generalizados
(GLMs) y sus peculiaridades matemáticas. \label{glms}

\normalsize

¿Cómo se estiman los parámetros $\bm{\Theta}$ del modelo? Los
algoritmos y heurísticas de optimización son muchos. Una vez más, aquí
se describirá la forma más propia y general de asignar valores a
variables no libres de estos o cualesquiera otros modelos estadísticos
paramétricos: la estimación por máxima probabilidad _a posteriori_
(Maximum A Posteriori: MAP), y el subcaso de estimación por máxima
verosimilitud (Maximum Likelihood Estimation: MLE) [@sorenson-1980;
@christensen-2002].

La estimación está constreñida a trabajar óptimamente con datos
limitados. Imagine que conoce la distribución de probabilidad de
observar ciertos valores de los parámetros del modelo, para todas las
posibles muestras de datos que de él emanaron
($P(\bm{\Theta}|\bm{Y})$). Entonces lo mejor que se podría hacer es
tomar los parámetros más probables. No obstante, eso es exactamente lo
que se ignora. No obstante, se puede recurrir al teorema de Bayes para
descomponer la distribución condicional:

$$ \overbrace{P(\bm{\Theta}|\bm{Y})}^{posterior} = \frac{\overbrace{P(\bm{Y}|\bm{\Theta})}^{verosimilitud} \;\; \overbrace{P(\bm{\Theta})}^{a\;priori\;(sesgo)} } {\underbrace{P(\bm{Y})}_{evidencia} } $$ {#eq:}

$P(\bm{Y})$ es uniforme si la respuesta realmente es lineal y si se
muestrea uniformemente en $\bm{X}$, por lo que su efecto sólo es el de
normalizar el numerador, y se ignora. A menos que se quiera incorporar
un sesgo con conocimiento previo acerca de $P(\bm{\Theta})$ — razón de
ser de la tradición estadística bayesiana — se asume que su
distribución es uniforme y también se ignora. Lo único que resta es
modelar la verosimilitud y maximizarla [@devore-2011].

A continuación se expone el método de MLE para el caso de regresión
lineal simple (una sola variable y un solo parámetro $\theta$ en
representación de la pendiente). Luego se extenderá la solución para
todo modelo lineal general.

Se asumirá que los ensayos de medición son independientes (la
probabilidad de observar algún valor no depende de lo observado en
otros ensayos, ó $P(y_i|y_j) = P(y_i)$); de manera que se pueda
aplicar la regla del producto para simplificar el cálculo de
probabilidades conjuntas. Expresado en notación matemática,
$P(y_i,\;y_j)$ en general es $P(y_i|y_j)P(y_j)$, pero la independencia
lo reduce a $P(y_i)P(y_j)$:

$$ P(\bm{y}|\theta) = P(y_1,\;...\;,\;y_n |\theta) = \prod_{i=1}^{n} P(y_i|\theta) $$ {#eq:}

Supongamos que las mediciones $y_i$ para un mismo valor de $x$ se
ciñen a un ruido gaussiano, con media en el valor verdadero según la
recta de regresión. Esto ocurre sin ataduras al valor que $\theta$
resulte tener. Supongamos además que la varianza del ruido es la misma
a lo largo de la variable explicativa, condición conocida como
_homocedasticidad_, que permite repetir exactamente la misma
distribución de probabilidad en cada factor. Así se otorga forma
concreta a la función de verosimilitud [@devore-2011]:

$$ P(\bm{y}|\theta) = \mathcal{L}(\bm{y}, \theta) = \prod_{i=1}^{n} \mathcal{N}(\mu=x_i\theta,\;\sigma^2) $$ {#eq:}

Por conveniencia analítica y numérica,[^loglik] se acostumbra trabajar
con el logaritmo natural de $\mathcal{L}$. Ya que los logaritmos son
funciones monotónicas, se garantiza que ambas optimizaciones produzcan
resultados idénticos:[^prueba1]

[^prueba1]: Ver el _Apéndice 1: prueba 1_ para una demostración más completa.

[^loglik]: Retrospectivamente al uso de MLE, los fundamentos de la
    teoría de la información ofrecen fuertes argumentos para trabajar
    con logaritmos de probabilidades. No sorprendentemente, existe una
    equivalencia entre MLE y estimación por minimización de
    información. Ortogonalmente, la mayoría de los lenguajes de
    programación ofrecen números de punto flotante para implementar
    métodos numéricos. Este tipo de dato representa números reales con
    precisión limitada, y el error acumulado de multiplicarlos resulta
    peor que el de sumarlos.

$$ ln(\mathcal{L}(\bm{y}, \theta)) = ln \left( \prod_{i=1}^{n} \mathcal{N}(\mu,\sigma^2) \right) = \sum_{i=1}^{n} ln\left[ \frac{1}{\sigma\sqrt{2\pi}} e^{-\frac{1}{2}\left( \frac{y_i - \mu}{\sigma}\right)^2} \right] $$

$$ = -\frac{n}{2}\;ln(2\pi\sigma^2) -\frac{1}{2\sigma^2} \sum_{i=1}^{n} \left( y_i - \underbrace{x_i\theta}_{\mu} \right)^2 $$ {#eq:simple-linear-reg-loglik}

Encontrar el parámetro que maximiza la log-verosimilitud equivale a
encontrar dónde la derivada de la log-verosimilitud respecto al
parámetro es cero. $ln(\mathcal{L})$ como función de $\theta$
claramente es una función parabólica cóncava; por lo que el máximo es
único, ergo también hay un solo modelo lineal óptimo. Aunque no se
demostrará aquí, de hecho el máximo se obtiene sin percances para
cualquier distribución de la familia exponencial
[@nelder-wedderburn-1972]; aunque no siempre esté disponible en forma
de expresión analítica, teniendo que echar mano de optimización
numérica. Esta propiedad de todos los modelos lineales generalizados
es atractiva computacionalmente. Nótese también que desde el punto de
vista de la derivada, que eliminará el primer término por ser
constante, se ha obtenido la misma función de costo que si se hubiera
elegido arbitrariamente el error cuadrático medio (MSE) de los
residuos, como se hace con estimación ordinaria por mínimos cuadrados
(OLS). A saber, se está hablando de la función objetivo $\frac{1}{n}
\sum_{i=1}^{n} \left( y_i - x_i\theta \right)^2$.

De vuelta con la derivada y sustituyendo $ln(\mathcal{L})$ por el
resultado de la ecuación (@eq:simple-linear-reg-loglik):[^prueba2]

[^prueba2]: Ver el _Apéndice 1: prueba 2_ para una demostración más completa.

$$ \hat{\theta} = arg_\theta max \;\; ln(\mathcal{L}) = \left\{ \theta : 0 = \frac{\partial ln(\mathcal{L})}{\partial\theta} \right\} $$

$$ = \frac{\sum_{i=1}^n x_i y_i}{\sum_{i=1}^n x_i^2} = \frac{ \bm{x} \cdot \bm{y} }{ \bm{x} \cdot \bm{x} } = \frac{Cov(x,y)}{Var(x)}$$ {#eq:normal-eq-simple}

La expresión anterior es conocida como _ecuación normal_, y permite
ajustar óptimamente la pendiente del modelo en un solo paso
[@devore-2011]. Podría seguirse un esquema de demostración similar
para obtener que el estimador por máxima verosimilitud de la varianza
del ruido gaussiano es, no sorprendentemente, la conocida fórmula de
la varianza [@devore-2011]:[^prueba3]

[^prueba3]: Ver el _Apéndice 1: prueba 3_ para una demostración más completa.

$$ \hat{\sigma}^2 = arg_{\sigma^2} max \;\; ln(\mathcal{L}) = \left\{ \sigma^2 : 0 = \frac{\partial ln(\mathcal{L})}{\partial\sigma^2} \right\} $$

$$ = \frac{1}{n} \sum_{i=1}^{n} (y-\mu)^2 = Var(y) $$ {#eq:}

Teniendo la pendiente $\theta$ y la media $\mu_y$ observada
empíricamente para cierto valor fijo de $x$, obtener el parámetro de
ordenada al origen se vuelve trivial. Éste parámetro también podría
obtenerse durante la mismo paso de MLE, añadiendo otra entrada al
vector $\bm{\theta}$ en un modelo lineal general, haciendo que su
respectiva columna en la matriz de diseño sea $(1 \; ... \; 1)^T$. Se
puede probar usando los mismos razonamientos que el modelo lineal
general o de regresión lineal múltiple tiene una ecuación normal
análoga a la ecuación (@eq:normal-eq-simple) de la regresión lineal
simple [@christensen-2002]. Para ser precisos:

$$ \hat{\bm{\theta}} = (\bm{X}^T \bm{X})^{-1}\bm{X}^T\bm{y} $$ {#eq:}

O más generalmente, para ajustar todos los modelos simultáneamente en
una operación matricial (por ejemplo, cuando se quiere ajustar el GLM
de cada serie de tiempo):

$$ \hat{\bm{\Theta}} = (\bm{X}^T \bm{X})^{-1}\bm{X}^T\bm{Y} $$ {#eq:}

### Análisis clásico vs MVPA

En cambio se podrían considerar todas las señales cerebrales
simultáneamente como sistema y tratar de predecir con ellas la
manipulación experimental: para cada instante, cada una de estas
señales aporta una coordenada para localizar el estado actual del
sistema. Entonces podemos pensar que el video completo de fMRI es
equivalente a un punto que se mueve en un espacio de muchas
dimensiones, tantas como voxeles, y su trayectoria en éste podría ir
prefiriendo zonas según cambian las variables experimentales. Si se
busca predecir valores continuos en la variable dependiente entonces
se sigue hablando de métodos de regresión multivariada (de hecho GLM
podría llegar a usarse de esta manera poco canónica para neuroimagen
funcional. El estudio de @stringer-et-al-2019 es muestra de ello). Si
la variable a predecir toma valores discretos entonces no se habla de
regresión, sino de clasificación. Más al respecto en breve.

Esta representación geométrica del sistema dinámico es conocida como
"espacio de estados", o "espacio fase" en física. El espacio fase
contiene exactamente la misma información que la secuencia de
imágenes. Todo abordaje analítico a los datos tiene un análogo en
espacio fase. Por ejemplo, un análisis de conectividad funcional
mediante correlación lineal es reducible a cuantificar la preferencia
del sistema a moverse a lo largo de diagonales entre los ejes. Como
veremos enseguida, el análisis clásico por GLM tiene cabida de la misma
manera usando esta representación.

En este punto se vuelve clara la limitante del análisis por GLM: asume
que el correlato neural yace en sitios individuales. Siguiendo con
nuestra representación de varios voxeles, podemos fácilmente concebir
patrones de actividad cerebral para los cuales GLM es más que
suficiente, pero también otros para los que fracasaría en distinguir
los estados.

Los diversos métodos multivariantes han demostrado tener mayor
sensibilidad extendiendo la identificación de interacciones complejas
de actividad cerebral que no son abordables mediante modelos de
regresión tradicionales [@huettel-et-al-2009; @mahmoudi-et-al-2012;
@lewis-peacock-norman-2013]. Agrupados bajo el nombre de "análisis de
patrones multivoxel" en la literatura neurocientífica (MVPA por sus
siglas en inglés), todos ellos comparten la característica de modelar
la codificación del estado mental, cognitivo o conductual como una
función de muchas dimensiones; que en el caso de fMRI toman la forma
de voxeles distantes en espacio o tiempo [@norman-et-al-2006;
@huettel-et-al-2009; @mahmoudi-et-al-2012; @lewis-peacock-norman-2013]

![Representando la función cerebral como un sistema dinámico. Una
secuencia de imágenes funcionales (izquierda) es equivalente a la
trayectoria de un punto en espacio fase (derecha), con una dimensión
distinta para cada señal BOLD (centro). Aquí solo se han seleccionado
tres
dimensiones. \label{dynsyst}](source/figures/dynamical-system.svg){height=15%}

Considere el siguiente ejemplo en el que el patrón de activación (ej.,
la señales de actividad en distintas áreas del cerebro) bajo dos
condiciones o macroestados experimentales, llamados _A_ y _B_, ha sido
construido según la siguiente relación (reducida a dos voxeles por
simplicidad):

$$ \left\{ \begin{array}{cc}
                           A: & voxel_1^2 + voxel_2^2 > r^2 \\
                           B: & voxel_1^2 + voxel_2^2 < r^2
           \end{array} \right. $$ {#eq:math-circle}

Esto no es más que un círculo en el espacio fase. Si restringimos los
valores a un intervalo finito y constante centrado en $(0,0)$, llamado
$c$, entonces podemos obligar a los macroestados _A_ y _B_ a poseer el
mismo número de puntos; si y solo si $r$ en la expresión
(@eq:math-circle) cumple que $\frac{c^2}{2} = \pi r^2$.

Luego, se muestrean algunos puntos aleatoriamente de manera uniforme
(40 en la figura \ref{lm-vs-multivariate}). Al graficarlos en el
plano, se observa que nuestras mediciones contienen suficiente
información para distinguir ambos estados cerebrales, incluso por
simple inspección visual. Aunque la actividad de ningún voxel
correlaciona con que el estímulo haya sido "círculo" o "triángulo", un
patrón discriminante emerge de la actividad conjunta. MVPA no es más
que el uso de algoritmos de aprendizaje automático para distinguir
esos patrones. En el caso del aprendizaje supervisado o clasificación,
lo que se pretende es construir una frontera capaz de catalogar los
datos.

Sin embargo un análisis univariado (como regresión mediante GLM) está
destinado a fracasar (ver figura \ref{lm-vs-multivariate}). Las
distribuciones unidimensionales de muestra se encuentran
aproximadamente centradas alrededor del mismo valor de intensidad, así
que no se observa ningún efecto intercondición. Por otro lado, las
mediciones están muy dispersas y lucen ruidosas. Tal enormidad en el
rango de valores para cada estado tampoco puede ser explicado por
artefactos de movimiento ni por un proceso determinista no
estacionario que empuje sistemáticamente los valores; ya que el
proceso usado para generar los estados fue explícitamente ninguna de
esas cosas.

![Izquierda: patrón bidimensional no lineal de actividad de dos
voxeles, según se muestreó aleatoriamente con 18 ensayos bajo la
condición experimental _A_ más 22 bajo la _B_. Las mediciones de la
señales que corresponden a la condición _A_ pueden distinguirse por su
excentricidad con respecto de la condición _B_. Derecha: modelos de
regresión lineal simplificados y valores $p$ de las pruebas $t$ para
las proyecciones de los datos de la figura izquierda sobre cada
eje. El efecto de las condiciones experimentales sobre voxeles
individuales es negligible (atestiguado por las pequeñas pendientes de
los modelos), y probablemente son resultado del azar (valores $p$),
como se esperaba. También por construcción, una prueba de Shapiro-Wilk
revela que las distribuciones de datos _A_ no lucen gaussianas,
haciendo más cuestionable la aplicación de este tipo de
análisis. \label{lm-vs-multivariate}](source/figures/./lm-vs-multivariate.svg){width=85%}

Incluso un clasificador univariado no lineal cometería una gran
cantidad de errores en la intersección entre ambas
distribuciones.[^uni-curvo] Un patrón discriminante univariado podría
observarse a partir de un análisis dinámico del espectro de
frecuencias bajo condiciones dinámicas especiales,[^fourier] pero el
enfoque más adecuado por mucho es considerar ambos voxeles
simultáneamente; como en la figura \ref{lm-vs-multivariate}, ya que
así es como se generaron los datos en primer lugar.

[^uni-curvo]: Imagine que todos los puntos de un voxel son colocados
    sobre la recta real, y permitimos dibujar una curva continua sobre
    todo el plano, con tal de separar las dos condiciones.

[^fourier]: Si las oscilaciones de la trayectoria durante un estado
    fueran más rápidas, por ejemplo. O más generalmente, en la medida
    en que su descomposición de Fourier favorezca frecuencias
    exclusivas.

Los beneficios son claros, pero no se adquieren sin desventajas. En
primer lugar el cómputo se vuelve más complejo. Ya no se analizan
voxeles, sino combinaciones de voxeles, algunas útiles para embargar
buen desempeño del modelo predictivo. Muchas otras sólo serán
detrimentales. Bastan unos cuantos cientos de señales para que el
número de combinaciones rápidamente exceda el número de átomos en el
universo observable. Las toscas imágenes de fMRI suelen contener
decenas de miles de series de tiempo.

## MVPA en neuroimagen funcional afectiva

Dada esta limitante en los métodos clásicos de análisis de patrones
diferenciales de activación en fMRI y PET, el campo de neuroimagen
funcional orientada a tareas comienza a recurrir a análisis
verdaderamente multivariados para dilucidar las preguntas de
interés. Al considerarlas holísticamente, MVPA es capaz de extraer
igual o mayor información de las burdas imágenes funcionales en la
mayoría de los casos [ver @jimura-poldrack-2012 para contraejemplos],
a expensas de complicar potencialmente el modelo y su cómputo. La
adopción de este enfoque en estudios con fMRI ha llevado a
descubrimientos novedosos en casi todas las ramales de la neurociencia
cognitiva [por ejemplo @haynes-rees-2005; @polyn-et-al-2005;
@soon-et-al-2008; @rissman-wagner-2012; véanse @huettel-et-al-2009;
@tong-pratte-2012 para más].

Según @lewis-peacock-norman-2013, el término MVPA es usado para
referirse a dos estrategias distintas de análisis de patrones
multivoxel; ambas provenientes del campo de estudio en el que se
intersecan la estadística inferencial multivariada y la inteligencia
artificial, un área conocida como "aprendizaje de máquinas" o "aprendizaje
automático" ("machine learning" en inglés):

- Clasificación automática empleando algoritmos de aprendizaje
   supervisado.
- Cuantificación de similitud entre patrones, según alguna métrica de
   distancia.

Mientras que los primeros decodifican estados preestablecidos a partir
de la actividad registrada, la segunda línea de análisis se asemeja a
la teoría de los modelos de aprendizaje automático no supervisado; y
puede entre otras cosas usarse para discernir si dos zonas del sistema
nervioso codifican información similar [@kriegeskorte-et-al-2008;
@walther-et-al-2016].

Para 2012 ya se habían realizado un puñado de estudios de
decodificación emocional con análisis multivariado, y su potencial era
reconocido por la comunidad en trabajos revisorios [como @hamann-2012;
o @schirmer-adolphs-2017 en lo que respecta a percepción emocional;
ver @kragel-labar-2014; y @kragel-labar-2016 para revisiones abocadas
al uso de MVPA en materia de emociones]. También es necesario recalcar
que aunque muchas de las aplicaciones de MVPA en neurociencia afectiva
han usado percepción de estímulos emocionalmente cargados, ésta no es
exactamente análoga a la experiencia en primera persona de una emoción
(notable también a partir de actividad cerebral
[@wager-et-al-2008]). La percepción de emociones en estímulos sociales
además puede involucrar procesos de evaluación, atribución de estados
mentales e intenciones; a la vez que puede estar exenta de emoción
_per se_ (debido a la modulación empática y sus trastornos)
[@peelen-et-al-2010]. Con todo y eso, ambos procesos parecen compartir
muchos circuitos de evaluación de carga emocional. En lo subsecuente
se hará la distinción, poniendo énfasis en los trabajos relativos a
_clasificación_ de estados de _percepción_ emocional.

La tabla \ref{table-mvpa-in-emotion-perception} enlista todos los
estudios encontrados para clasificación de percepción emocional y
algún otro. Éstos pueden ser tamizados según la modalidad de los
estímulos, las emociones probadas, si la búsqueda se concentra en
regiones de interés o si se hizo algo más parecido a un análisis de
cerebro completo. También, por el algoritmo de clasificación, y
obviamente por sus resultados. La forma más sucinta de expresar el
resultado es comparando la capacidad de clasificar correctamente los
patrones cerebrales (exactitud) respecto de un desempeño por
azar. Observamos que si bien no son perfectos, siempre se ha reportado
evidencia de estar por encima del azar.

@pessoa-padmala-2007 demostraron la factibilidad de usar MVPA para
predecir la respuesta conductual en una tarea de fMRI sobre percepción
de caras asustadas, presentadas casi subliminalmente, en contraste con
otros tipos de caras. Se basó en un algoritmo de entrenamiento SVM sin
kernel, cuyo desempeño aumentaba conforme las variables independientes
en el modelo eran adicionadas con nuevas regiones de interés (ROIs por
sus siglas en inglés); hipotetizando que los varios aspectos de la
actividad emocional (discriminación del estímulo, producción de
respuestas, etc.)  contienen información útil para recuperar el estado
perceptual. @ethofer-et-al-2009 utilizaron estímulos auditivos con
carga paralingüística emocional. Su modelo SVM fue capaz de clasificar
entre cuatro emociones básicas y un estado aemocional por encima del
azar, mientras que un análisis univariado no encontró diferencias en
las mismas señales BOLD, provenientes de corteza auditiva (ver
@kotz-et-al-2012 para un estudio similar no restringido a corteza
auditiva). @said-et-al-2010 utilizaron clasificación multivariada
mediante el método de regresión logística para demostrar que la
actividad de ciertas regiones del surco temporal superior (STS,
previamente vinculadas a detección de expresiones faciales) predice la
categoría emocional de los rostros. Los mismos datos bajo análisis
univariado fueron incapaces de repetir la hazaña. @peelen-et-al-2010
hicieron un estudio de similitud de patrones, probando estímulos de
cinco categorías emocionales en modalidades distintas (audición,
visión de gesticulaciones y de lenguaje corporal), y realizaron una
búsqueda de regiones codificantes en todo el encéfalo mediante el
método de "searchlight". Sorprendentemente, en la corteza prefrontal
medial (mPFC) y en el STS posterior, los patrones de actividad son más
similares entre sí cuando se agrupan por emociones que
por  modalidad sensorial o intensidad del
estímulo. En cambio, la aplicación de GLM sólo replicó este hallazgo
supramodal en el caso del miedo. @wegrzyn-et-al-2015 exploraron varias
ROIs asociadas a procesamiento de rostros para comparar la magnitud en
la que contienen información emocional. Todas resultaron aptas,
especialmente el STS y la bien conocida FFA (especialmente la derecha,
convergiendo con el conocimiento previo).

El uso de MVPA en predicción de percepción emocional también ha
alcanzado a otros modelos de las emociones y a otras
especies. @skerry-saxe-2015 utilizaron SVM para probar que las
emociones percibidas, entendidas como "appraisals" o evaluaciones
sociales finas y dependientes del contexto, pueden decodificarse por
encima del azar a partir de redes cerebrales asociadas a la facultad
de teoría de la mente.  @hernandez-et-al-2018 (prepublicación)
entrenaron perros para permanecer quietos y despiertos en un resonador
magnético mientras observaban rostros humanos felices o
inexpresivos. En un segundo experimento emplearon más emociones y SVM
para proveer evidencia de que los correlatos encontrados en la corteza
temporal derecha del perro contienen información selectiva a la
felicidad de los humanos.

En lo que respecta a experimentación en primera persona de emociones,
los métodos de clasificación multivariada han sido capaces de
caracterizar con precisión los dispersos correlatos espaciales de la
valencia hedonística y el nivel de excitación (arousal) postulados por
hipótesis dimensionales [@rolls-et-al-2009; @baucom-et-al-2012;
@chikazoe-et-al-2014; @shinkareva-et-al-2014;
@chang-et-al-2015]. Además hay evidencia de cierta generalidad
intersujeto, pues existen patrones compartidos que permiten su
clasificación a niveles de exactitud no triviales. De la misma forma
se han encontrado resultados prometedores categorizando experiencias
de emociones discretas (así se quieran conceptualizar como básicas o
constructos), en comparación con los resultados del cúmulo de
literatura con análisis univariado [@sitaram-et-al-2011;
@kassam-et-al-2013; @saarimaki-et-al-2015; @kragel-labar-2015]. Está
por verse si el uso de MVPA será suficiente para encontrar una
hipótesis vencedora.\newline

\newpage

\scriptsize

| **Estudio** | **Modalidad de estímulo** | **Emoción de estímulo** | **ROI** | **Algoritmo** | **Desempeño** |
|-|-|-|-|-|-|
| @pessoa-padmala-2007 | visual | miedo | varias | SVM | 78% > 50% |
| | | | | | |
| @ethofer-et-al-2009 | auditiva | alegría, enojo, tristeza, alivio | corteza auditiva | SVM | 33% > 20% |
| | | | | | |
| @said-et-al-2010 | visual | alegría, enojo, tristeza, asco, sorpresa, miedo | surco temporal superior, opérculo frontal | regresión logística multinomial regularizada (SMLR) | 22% > 14% |
| | | | | | |
| @peelen-et-al-2010 | auditiva, visual (gesticulaciones, lenguaje corporal) | alegría, enojo, tristeza, asco, miedo | encéfalo (searchlight) | RSA | RSA |
| | | | | | |
| @kotz-et-al-2012 | auditiva | alegría, enojo, tristeza, sorpresa | encéfalo (searchlight) | SVM | 28% > 20% |
| | | | | | |
| @skerry-saxe-2015 | lectura, visual (caras) | 21 distinciones finas contexto-dependientes (appraisals) | red de teoría de la mente, encéfalo (searchlight) | SVM | ~8% > 5% (ROIs) |
| | | | | | |
| @wegrzyn-et-al-2015 | visual (caras) | alegría, enojo, miedo | varias | MGPC | ~32% > 25% |
| | | | | | |
| @hernandez-et-al-2018 | visual (caras) | alegría | (_canis familiaris_) corteza temporal derecha, caudado. Encéfalo (searchlight) | SVM | ~65% > 50% (ROIs) |

Table: Muestra representativa de estudios experimentales con MVPA que
versan sobre los correlatos neurales de la percepción de
emociones. \label{table-mvpa-in-emotion-perception}

\normalsize

<!-- Descubrimientos en pacientes con daño cerebral, estudios de -->
<!-- imagenología y de estimulación han establecido la segregación de dos -->
<!-- sistemas distintos de atención visual en humanos; que abarcan, -->
<!-- respectivamente, sitios dorsales y ventrales en lóbulos frontales y -->
<!-- parietales [@vossel-et-al-2014; @umarova-et-al-2009].[^what-vs-where] -->
<!-- La primera es responsable por una forma de atención dirigida por -->
<!-- objetivos (_top-down_), mientras que la segunda reacciona a estímulos -->
<!-- inesperados (_bottom-up_). Además se ha sugerido que sirven como -->
<!-- mecanismos atencionales genéricos independientemente de la modalidad -->
<!-- sensorial [@macaluso-2010], e incluso estando carente información de -->
<!-- carácter conceptual o integrativo (por ejemplo, durante una tarea de -->
<!-- selección basada en características) [@vandenberghe-gillebert-2009]. -->

<!-- [^what-vs-where]: No deben confundirse con las también dorsal y -->
<!-- ventral vías del "dónde" y del "qué" en percepción visual. Aunque -->
<!-- podría existir traslape con las redes de atención en la unión -->
<!-- temporoparietal y el surco intraparietal. -->

<!-- La indagación en la conectividad funcional, causal y estructural de -->
<!-- las redes dorsal y ventral ha comenzado a echar luz sobre sus -->
<!-- componentes, y — en menor grado — sus especializaciones. La red dorsal -->
<!-- comprende cuando menos los campos oculares frontales (FEF en inglés) y -->
<!-- surco intraparietal (IPS); ambos de los cuales se piensa muestran -->
<!-- tractos de asociación con las áreas perceptuales del lóbulo occipital, -->
<!-- de organización contralateral retinotópica; así como fibras de comisura -->
<!-- para conectar hemirredes homólogas. Es posible que la red dorsal esté -->
<!-- computando mapas de prominencia planificada, como es sugerido por la -->
<!-- presencia de incluso más campos receptivos retinotópicamente -->
<!-- organizados en FEF e IPS. Estos mapas de "saliencia" serían consumidos -->
<!-- por FEF para solicitar toda clase de movimientos oculares -->
<!-- [@jerde-et-al-2012]. -->

<!-- El funcionamiento interno de la red ventral frontoparietal está menos -->
<!-- dilucidado, pero se ha asociado fiablemente al filtro de eventos -->
<!-- exógenos (o sea, irrelevantes a la tarea); presumiblemente permitiendo -->
<!-- que estímulos inesperados y potencialmente peligrosos se sobrepongan a -->
<!-- la concentración del sujeto y pasen al foco de atención. La activación -->
<!-- ocurre en las zonas denominadas unión temporoparietal (TPJ) y la -->
<!-- corteza ventral frontal (VFC). Existen problemas determinando si la -->
<!-- red ventral está lateralizada hacia el hemisferio derecho, y no hay -->
<!-- algún estandar citoarquitectónico (o de otro tipo) que delimite estas -->
<!-- áreas [@vossel-et-al-2014]. -->

<!-- TPJ ha sido postulada como un punto de interacción entre sistemas -->
<!-- [@corbetta-et-al-2008; @fox-et-al-2006]. La actividad intrínseca del -->
<!-- giro frontal medio (MFG) posterior derecho está correlacionada con -->
<!-- ambas redes; convirtiéndola en otro _hub_ candidato. De los tres -->
<!-- principales fascículos longitudinales superiores (SFL I, II y III) que -->
<!-- proveen conexiones anatómicas asociativas para estas redes, se sabe -->
<!-- que el de en medio (SFL II) conecta a FEF y TPJ -->
<!-- [@de-schotten-et-all-2011]. -->

<!-- ## A favor y en contra de la percepción emocional automática -->

<!-- El paradigma de _priming_ afectivo [@klauer-musch-2003] tiene efectos -->
<!-- mejorando tiempos de reacción y exactitud en la identificación de -->
<!-- emociones idénticas consecutivas, lo cual refleja cierta versatilidad -->
<!-- en el proceso que desemboca en el reconocimiento afectivo -->
<!-- [@de-houwer-2009]. Varias líneas de evidencia ayudan a extrapolar este -->
<!-- hecho hacia la noción de que la percepción afectiva puede someterse a -->
<!-- un modo automático/preatencional: -->

<!-- - Debido a que el priming afectivo sólo ocurre bajo tiempos cortos de -->
<!--   asincronía de puesta de estímulo (_SOA_[^soa] en inglés) (300 ms o -->
<!--   menos), se conjetura que el procesamiento del estimulo primal debe -->
<!--   ocurrir antes de que dé lugar el despliegue de atención y -->
<!--   estrategias de respuesta [@moors-de-houwer-2006; -->
<!--   @hermans-et-al-2001]. -->

<!-- [^soa]: El lapso de tiempo entre estímulo primal y la presentación del -->
<!--     sengundo. -->

<!-- - El efecto se observa incluso cuando el primal se presenta en niveles -->
<!--   subumbrales, irreconocibles [@draine-greenwald-1998] y fuera del -->
<!--   foco de atención visual [@calvo-nummenmaa-2007]. -->

<!-- - Según algunos reportes, la carga cognitiva (producida por la -->
<!--   presentación simultánea de tareas irrelevantes) no impacta en el -->
<!--   _priming_ [@hermans-et-al-2000]. No obstante esto está en pugna. -->

<!-- Un refinamiento posterior propone que no todas las emociones fueron -->
<!-- hechas igualmente ventajosas de reconocer. Si la selección natural -->
<!-- produjo circuitería neuronal complementaria de alta prioridad para el -->
<!-- procesamiento de expresiones faciales (o un precursor epigenético), -->
<!-- uno puede naturalmente preguntar si este automatismo también -->
<!-- seleccionó algunas emociones más que otras; con base en su ventaja de -->
<!-- supervivencia. En efecto, un cúmulo de investigaciones han encontrado -->
<!-- que el efecto de _priming_, así como otros, están sesgados hacia -->
<!-- emociones aversivas o peyorativas en contraposición a las -->
<!-- satisfactorias o neutras [@fox-et-al-2002; @vuilleumier-2001; -->
<!-- @ishai-et-al-2004; @vuilleumier-2005; @susa-et-al-2012]. -->

<!-- En oposición a la visión anterior, @pessoa-et-al-2002 interpretaron el -->
<!-- incremento en actividad en estructuras corticales y basales ligadas al -->
<!-- reconocimiento facial y emocional (giro fusiforme, amígdala, etc.) -->
<!-- durante atención explícita a rostros (en contraste con detalles no -->
<!-- expresivos inscritos en las caras) como evidencia de que el -->
<!-- procesamiento facial es contingente a la atención. Esta veta de -->
<!-- estudios en procesamiento de emociones faciales posee simpatizantes -->
<!-- recientes [véase @ochsner-gross-2005; @eimer-et-al-2003 por -->
<!-- ejemplo]. De los estudios con EEG[^eeg] que tratan de correlacionar -->
<!-- supuestos índices por PREs[^erp] de atención visual con diversos modos -->
<!-- de percepción emocional se han obtenido resultados dispares (ver -->
<!-- revisión y resultados negativos de @galfano-et-all-2011 concernientes -->
<!-- a la hipótesis de sesgo dependiente a la emoción, según se infiere de -->
<!-- los segundos componentes negativos de señales de electrodos -->
<!-- posteriores contralaterales durante una tarea de pista por mirada -->
<!-- (_gaze cuing_)). -->

<!-- [^eeg]: Electroencefalografía. -->
<!-- [^erp]: Potencial relacionado con eventos. A veces usado -->
<!--     intercambiablemente con "potencial evocado". -->

<!-- Resultados contradictorios producto de experimentos metodológicamente -->
<!-- sólidos demandan una reformulación teórica capaz de cobijar todos los -->
<!-- hechos. Las investigaciones en torno al conflicto suelen invocar -->
<!-- alguna forma de interacción o modulación entre sistemas para poder -->
<!-- explicar los datos [@okon-et-al-2007; @palermo-rhodes-2007]. Basados -->
<!-- en tiempos de reacción y variabilidad en la dificultad de la tarea, -->
<!-- Sassi y colegas propusieron que a pesar de que la percepción emocional -->
<!-- puede volverse automática, los recursos sobrantes podrían seguir -->
<!-- siendo usados en paralelo para el mismo propósito si los distractores -->
<!-- no fueran suficientes [@sassi-et-al-2014]. -->
